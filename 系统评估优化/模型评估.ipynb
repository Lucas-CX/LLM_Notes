{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../构建知识库\") # 将父目录放入系统路径中\n",
    "\n",
    "# 使用智谱 Embedding API，注意，需要将上一章实现的封装代码下载到本地\n",
    "from zhipuai_embedding import ZhipuAIEmbeddings\n",
    "\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv())    # read local .env file\n",
    "zhipuai_api_key = os.environ['ZHIPUAI_API_KEY']\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# 定义 Embeddings\n",
    "embedding = ZhipuAIEmbeddings()\n",
    "\n",
    "# 向量数据库持久化路径\n",
    "persist_directory = '../data_base/vector_db/chroma'\n",
    "\n",
    "# 加载数据库\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,  # 允许我们将persist_directory目录保存到磁盘上\n",
    "    embedding_function=embedding\n",
    ")\n",
    "\n",
    "# 使用 OpenAI GPT-3.5 模型\n",
    "llm = ChatOpenAI(model_name = \"gpt-3.5-turbo\", temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题一：\n",
      "南瓜书是对西瓜书中难以理解的公式进行解析和补充推导细节的书籍。\n",
      "谢谢你的提问！\n",
      "问题二：\n",
      "南瓜书的最佳使用方法是以西瓜书为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书。谢谢你的提问！\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "template_v1 = \"\"\"使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答\n",
    "案。最多使用三句话。尽量使答案简明扼要。总是在回答的最后说“谢谢你的提问！”。\n",
    "{context}\n",
    "问题: {question}\n",
    "\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\",\"question\"],\n",
    "                                 template=template_v1)\n",
    "\n",
    "\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=vectordb.as_retriever(),\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"prompt\":QA_CHAIN_PROMPT})\n",
    "\n",
    "print(\"问题一：\")\n",
    "question = \"南瓜书和西瓜书有什么关系？\"\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result[\"result\"])\n",
    "\n",
    "print(\"问题二：\")\n",
    "question = \"应该如何使用南瓜书？\"\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题：\n",
      "应该如何使用南瓜书？\n",
      "模型回答：\n",
      "南瓜书的最佳使用方法是以西瓜书为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书。谢谢你的提问！\n"
     ]
    }
   ],
   "source": [
    "print(\"问题：\")\n",
    "question = \"应该如何使用南瓜书？\"\n",
    "print(question)\n",
    "print(\"模型回答：\")\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；\\n• 对于初学机器学习的小白，西瓜书第1 章和第2 章的公式强烈不建议深究，简单过一下即可，等你学得\\n有点飘的时候再回来啃都来得及；\\n• 每个公式的解析和推导我们都力(zhi) 争(neng) 以本科数学基础的视角进行讲解，所以超纲的数学知识\\n我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；\\n• 若南瓜书里没有你想要查阅的公式，\\n或者你发现南瓜书哪个地方有错误，\\n请毫不犹豫地去我们GitHub 的\\nIssues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块\\n提交你希望补充的公式编号或者勘误信息，我们通常会在24 小时以内给您回复，超过24 小时未回复的\\n话可以微信联系我们（微信号：at-Sm1les）\\n；\\n配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU', metadata={'author': '', 'creationDate': \"D:20230303170709-00'00'\", 'creator': 'LaTeX with hyperref', 'file_path': '../data_base/knowledge_db\\\\pumkin_book\\\\pumpkin_book.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': '', 'page': 1, 'producer': 'xdvipdfmx (20200315)', 'source': '../data_base/knowledge_db\\\\pumkin_book\\\\pumpkin_book.pdf', 'subject': '', 'title': '', 'total_pages': 196, 'trapped': ''}), Document(page_content='在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第1 版）\\n最新版PDF 获取地址：https://github.com/datawhalechina/pumpkin-book/releases\\n编委会\\n主编：Sm1les、archwalker、jbb0523\\n编委：juxiao、Majingmin、MrBigFan、shanry、Ye980226\\n封面设计：构思-Sm1les、创作-林王茂盛\\n致谢\\n特别感谢awyd234、\\nfeijuan、\\nGgmatch、\\nHeitao5200、\\nhuaqing89、\\nLongJH、\\nLilRachel、\\nLeoLRH、\\nNono17、\\nspareribs、sunchaothu、StevenLzq 在最早期的时候对南瓜书所做的贡献。\\n扫描下方二维码，然后回复关键词“南瓜书”\\n，即可加入“南瓜书读者交流群”\\n版权声明\\n本作品采用知识共享署名-非商业性使用-相同方式共享4.0 国际许可协议进行许可。', metadata={'author': '', 'creationDate': \"D:20230303170709-00'00'\", 'creator': 'LaTeX with hyperref', 'file_path': '../data_base/knowledge_db\\\\pumkin_book\\\\pumpkin_book.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': '', 'page': 1, 'producer': 'xdvipdfmx (20200315)', 'source': '../data_base/knowledge_db\\\\pumkin_book\\\\pumpkin_book.pdf', 'subject': '', 'title': '', 'total_pages': 196, 'trapped': ''}), Document(page_content='\\x01本\\x03:1.9.9\\n发布日期:2023.03\\n南  ⽠  书\\nPUMPKIN\\nB  O  O  K\\nDatawhale', metadata={'author': '', 'creationDate': \"D:20230303170709-00'00'\", 'creator': 'LaTeX with hyperref', 'file_path': '../data_base/knowledge_db\\\\pumkin_book\\\\pumpkin_book.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': '', 'page': 0, 'producer': 'xdvipdfmx (20200315)', 'source': '../data_base/knowledge_db\\\\pumkin_book\\\\pumpkin_book.pdf', 'subject': '', 'title': '', 'total_pages': 196, 'trapped': ''}), Document(page_content='前言\\n“周志华老师的《机器学习》\\n（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\\n者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\\n导细节的读者来说可能“不太友好”\\n，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\\n具体的推导细节。\\n”\\n读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周\\n老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书\\n中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”\\n。所以...... 本南瓜书只能算是我\\n等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二\\n下学生”\\n。\\n使用说明\\n• 南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书\\n为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；', metadata={'author': '', 'creationDate': \"D:20230303170709-00'00'\", 'creator': 'LaTeX with hyperref', 'file_path': '../data_base/knowledge_db\\\\pumkin_book\\\\pumpkin_book.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': '', 'page': 1, 'producer': 'xdvipdfmx (20200315)', 'source': '../data_base/knowledge_db\\\\pumkin_book\\\\pumpkin_book.pdf', 'subject': '', 'title': '', 'total_pages': 196, 'trapped': ''})]\n"
     ]
    }
   ],
   "source": [
    "print(result[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''\n",
    "请你做如下选择题：\n",
    "题目：南瓜书的作者是谁？\n",
    "选项：A 周志明 B 谢文睿 C 秦州 D 贾彬彬\n",
    "你可以参考的知识片段：\n",
    "```\n",
    "{}\n",
    "```\n",
    "请仅返回选择的选项\n",
    "如果你无法做出选择，请返回空\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是我们可以看到，我们要求模型在不能回答的情况下不做选择，而不是随便选。但是在我们的打分策略中，错选和不选均为0分，这样其实鼓励了模型的幻觉回答，因此我们可以根据情况调整打分策略，让错选扣一分："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_select_score_v1(true_answer : str, generate_answer : str) -> float:\n",
    "    # true_anser : 正确答案，str 类型，例如 'BCD'\n",
    "    # generate_answer : 模型生成答案，str 类型\n",
    "    true_answers = list(true_answer)\n",
    "    '''为便于计算，我们假设每道题都只有 A B C D 四个选项'''\n",
    "    # 先找出错误答案集合\n",
    "    false_answers = [item for item in ['A', 'B', 'C', 'D'] if item not in true_answers]\n",
    "    # 如果生成答案出现了错误答案\n",
    "    for one_answer in false_answers:\n",
    "        if one_answer in generate_answer:\n",
    "            return 0\n",
    "    # 再判断是否全选了正确答案\n",
    "    if_correct = 0\n",
    "    for one_answer in true_answers:\n",
    "        if one_answer in generate_answer:\n",
    "            if_correct += 1\n",
    "            continue\n",
    "    if if_correct == 0:\n",
    "        # 不选\n",
    "        return 0\n",
    "    elif if_correct == len(true_answers):\n",
    "        # 全选\n",
    "        return 1\n",
    "    else:\n",
    "        # 漏选\n",
    "        return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "答案一得分： 0.5\n",
      "答案二得分： 0\n",
      "答案三得分： 1\n",
      "答案四得分： 0\n"
     ]
    }
   ],
   "source": [
    "answer1 = 'B C'\n",
    "answer2 = '西瓜书的作者是 A 周志华'\n",
    "answer3 = '应该选择 B C D'\n",
    "answer4 = '我不知道'\n",
    "true_answer = 'BCD'\n",
    "print(\"答案一得分：\", multi_select_score_v1(true_answer, answer1))\n",
    "print(\"答案二得分：\", multi_select_score_v1(true_answer, answer2))\n",
    "print(\"答案三得分：\", multi_select_score_v1(true_answer, answer3))\n",
    "print(\"答案四得分：\", multi_select_score_v1(true_answer, answer4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_select_score_v2(true_answer : str, generate_answer : str) -> float:\n",
    "    # true_anser : 正确答案，str 类型，例如 'BCD'\n",
    "    # generate_answer : 模型生成答案，str 类型\n",
    "    true_answers = list(true_answer)\n",
    "    '''为便于计算，我们假设每道题都只有 A B C D 四个选项'''\n",
    "    # 先找出错误答案集合\n",
    "    false_answers = [item for item in ['A', 'B', 'C', 'D'] if item not in true_answers]\n",
    "    # 如果生成答案出现了错误答案\n",
    "    for one_answer in false_answers:\n",
    "        if one_answer in generate_answer:\n",
    "            return -1\n",
    "    # 再判断是否全选了正确答案\n",
    "    if_correct = 0\n",
    "    for one_answer in true_answers:\n",
    "        if one_answer in generate_answer:\n",
    "            if_correct += 1\n",
    "            continue\n",
    "    if if_correct == 0:\n",
    "        # 不选\n",
    "        return 0\n",
    "    elif if_correct == len(true_answers):\n",
    "        # 全选\n",
    "        return 1\n",
    "    else:\n",
    "        # 漏选\n",
    "        return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "答案一得分： 0.5\n",
      "答案二得分： -1\n",
      "答案三得分： 1\n",
      "答案四得分： 0\n"
     ]
    }
   ],
   "source": [
    "answer1 = 'B C'\n",
    "answer2 = '西瓜书的作者是 A 周志华'\n",
    "answer3 = '应该选择 B C D'\n",
    "answer4 = '我不知道'\n",
    "true_answer = 'BCD'\n",
    "print(\"答案一得分：\", multi_select_score_v2(true_answer, answer1))\n",
    "print(\"答案二得分：\", multi_select_score_v2(true_answer, answer2))\n",
    "print(\"答案三得分：\", multi_select_score_v2(true_answer, answer3))\n",
    "print(\"答案四得分：\", multi_select_score_v2(true_answer, answer4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法二：计算答案相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import jieba\n",
    "\n",
    "def bleu_score(true_answer : str, generate_answer : str) -> float:\n",
    "    # true_anser : 标准答案，str 类型\n",
    "    # generate_answer : 模型生成答案，str 类型\n",
    "    true_answers = list(jieba.cut(true_answer))\n",
    "    # print(true_answers)\n",
    "    generate_answers = list(jieba.cut(generate_answer))\n",
    "    # print(generate_answers)\n",
    "    bleu_score = sentence_bleu([true_answers], generate_answers)    # 传参需注意 二维、一维\n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "答案一：\n",
      "周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充具体的推导细节。\n",
      "得分： 1.0\n",
      "答案二：\n",
      "本南瓜书只能算是我等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二下学生”\n",
      "得分： 2.9890895980184603e-232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\miniconda3\\envs\\llm-universe\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "d:\\software\\miniconda3\\envs\\llm-universe\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "d:\\software\\miniconda3\\envs\\llm-universe\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "true_answer = '周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充具体的推导细节。'\n",
    "\n",
    "print(\"答案一：\")\n",
    "answer1 = '周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充具体的推导细节。'\n",
    "print(answer1)\n",
    "score = bleu_score(true_answer, answer1)\n",
    "print(\"得分：\", score)\n",
    "print(\"答案二：\")\n",
    "answer2 = '本南瓜书只能算是我等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二下学生”'\n",
    "print(answer2)\n",
    "score = bleu_score(true_answer, answer2)\n",
    "print(\"得分：\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，答案与标准答案一致性越高，则评估打分就越高。通过此种方法，我们同样只需对验证集中每一个问题构造一个标准答案，之后就可以实现自动、高效的评估。\n",
    "\n",
    "但是，该种方法同样存在几个问题：① 需要人工构造标准答案。对于一些垂直领域而言，构造标准答案可能是一件困难的事情；② 通过相似度来评估，可能存在问题。例如，如果生成回答与标准答案高度一致但在核心的几个地方恰恰相反导致答案完全错误，bleu 得分仍然会很高；③ 通过计算与标准答案一致性灵活性很差，如果模型生成了比标准答案更好的回答，但评估得分反而会降低；④ 无法评估回答的智能性、流畅性。如果回答是各个标准答案中的关键词拼接出来的，我们认为这样的回答是不可用无法理解的，但 bleu 得分会较高。\n",
    "\n",
    "因此，针对业务情况，有时我们还需要一些不需要构造标准答案的、进阶的评估方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用大模型进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "你是一个模型回答评估员。\n",
    "接下来，我将给你一个问题、对应的知识片段以及模型根据知识片段对问题的回答。\n",
    "请你依次评估以下维度模型回答的表现，分别给出打分：\n",
    "\n",
    "① 知识查找正确性。评估系统给定的知识片段是否能够对问题做出回答。如果知识片段不能做出回答，打分为0；如果知识片段可以做出回答，打分为1。\n",
    "\n",
    "② 回答一致性。评估系统的回答是否针对用户问题展开，是否有偏题、错误理解题意的情况，打分分值在0~1之间，0为完全偏题，1为完全切题。\n",
    "\n",
    "③ 回答幻觉比例。该维度需要综合系统回答与查找到的知识片段，评估系统的回答是否出现幻觉，打分分值在0~1之间,0为全部是模型幻觉，1为没有任何幻觉。\n",
    "\n",
    "④ 回答正确性。该维度评估系统回答是否正确，是否充分解答了用户问题，打分分值在0~1之间，0为完全不正确，1为完全正确。\n",
    "\n",
    "⑤ 逻辑性。该维度评估系统回答是否逻辑连贯，是否出现前后冲突、逻辑混乱的情况。打分分值在0~1之间，0为逻辑完全混乱，1为完全没有逻辑问题。\n",
    "\n",
    "⑥ 通顺性。该维度评估系统回答是否通顺、合乎语法。打分分值在0~1之间，0为语句完全不通顺，1为语句完全通顺没有任何语法问题。\n",
    "\n",
    "⑦ 智能性。该维度评估系统回答是否拟人化、智能化，是否能充分让用户混淆人工回答与智能回答。打分分值在0~1之间，0为非常明显的模型回答，1为与人工回答高度一致。\n",
    "\n",
    "你应该是比较严苛的评估员，很少给出满分的高评估。\n",
    "用户问题：\n",
    "```\n",
    "{}\n",
    "```\n",
    "待评估的回答：\n",
    "```\n",
    "{}\n",
    "```\n",
    "给定的知识片段：\n",
    "```\n",
    "{}\n",
    "```\n",
    "你应该返回给我一个可直接解析的 Python 字典，字典的键是如上维度，值是每一个维度对应的评估打分。\n",
    "不要输出任何其他内容。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"知识查找正确性\": 1,\\n  \"回答一致性\": 1,\\n  \"回答幻觉比例\": 0,\\n  \"回答正确性\": 1,\\n  \"逻辑性\": 1,\\n  \"通顺性\": 1,\\n  \"智能性\": 0.5\\n}'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# 使用第二章讲过的 OpenAI 原生接口\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "\n",
    "def gen_gpt_messages(prompt):\n",
    "    '''\n",
    "    构造 GPT 模型请求参数 messages\n",
    "    \n",
    "    请求参数：\n",
    "        prompt: 对应的用户提示词\n",
    "    '''\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    return messages\n",
    "\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature = 0):\n",
    "    '''\n",
    "    获取 GPT 模型调用结果\n",
    "\n",
    "    请求参数：\n",
    "        prompt: 对应的提示词\n",
    "        model: 调用的模型，默认为 gpt-3.5-turbo，也可以按需选择 gpt-4 等其他模型\n",
    "        temperature: 模型输出的温度系数，控制输出的随机程度，取值范围是 0~2。温度系数越低，输出内容越一致。\n",
    "    '''\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=gen_gpt_messages(prompt),\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    if len(response.choices) > 0:\n",
    "        return response.choices[0].message.content\n",
    "    return \"generate answer error\"\n",
    "\n",
    "question = \"应该如何使用南瓜书？\"\n",
    "result = qa_chain({\"query\": question})\n",
    "answer = result[\"result\"]\n",
    "knowledge = result[\"source_documents\"]\n",
    "\n",
    "response = get_completion(prompt.format(question, answer, knowledge))\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-universe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
